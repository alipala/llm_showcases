{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization and setup libraries"
      ],
      "metadata": {
        "id": "aU1M0TTNm0Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vJNi7zhPm4gS",
        "outputId": "a13dca51-4e85-4adb-b4cd-91d24e818afd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.41.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading openai-1.41.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.4/362.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m91.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jiter, h11, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, nvidia-cusolver-cu12, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-1.41.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import textwrap\n",
        "import re\n",
        "from google.colab import drive\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "bN62eH_gnWnN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for persistent storage\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaUXDzu1ndiz",
        "outputId": "afb31802-92c7-4432-c953-d035f3f3c967"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client with your API key\n",
        "client = OpenAI(api_key=\"YOUR_OPEN_API_KEY\")"
      ],
      "metadata": {
        "id": "tg6dpcu3nkbh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize sentiment analysis pipeline\n",
        "try:\n",
        "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading sentiment analysis model: {e}\")\n",
        "    print(\"Falling back to a simpler sentiment analysis method.\")\n",
        "    sentiment_analyzer = None"
      ],
      "metadata": {
        "id": "HIOo6bTLnuaT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up and required steps for user profiling"
      ],
      "metadata": {
        "id": "tSVfTDwonzZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up profile storage in Google Drive\n",
        "PROFILES_FOLDER = '/content/drive/MyDrive/financial_advisor_profiles'\n",
        "if not os.path.exists(PROFILES_FOLDER):\n",
        "    os.makedirs(PROFILES_FOLDER)\n",
        "\n",
        "def generate_unique_id():\n",
        "    \"\"\"Generate a unique identifier for a user profile.\"\"\"\n",
        "    return str(uuid.uuid4())\n",
        "\n",
        "def save_profile(profile):\n",
        "    \"\"\"Save a user profile to a JSON file in Google Drive.\"\"\"\n",
        "    filename = os.path.join(PROFILES_FOLDER, f\"{profile['id']}.json\")\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(profile, f)\n",
        "\n",
        "def load_profile(profile_id):\n",
        "    \"\"\"Load a user profile from a JSON file in Google Drive.\"\"\"\n",
        "    filename = os.path.join(PROFILES_FOLDER, f\"{profile_id}.json\")\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return None\n",
        "\n",
        "def find_profile_by_name(name):\n",
        "    \"\"\"Find all profiles matching a given name.\"\"\"\n",
        "    matching_profiles = []\n",
        "    for filename in os.listdir(PROFILES_FOLDER):\n",
        "        if filename.endswith('.json'):\n",
        "            profile = load_profile(filename[:-5])\n",
        "            if profile and profile['name'].lower() == name.lower():\n",
        "                matching_profiles.append(profile)\n",
        "    return matching_profiles\n",
        "\n",
        "def create_new_profile(name):\n",
        "    \"\"\"Create a new user profile with synthetic spending data.\"\"\"\n",
        "    profile_id = generate_unique_id()\n",
        "    profile = {\n",
        "        \"id\": profile_id,\n",
        "        \"name\": name,\n",
        "        \"age\": None,\n",
        "        \"income\": None,\n",
        "        \"savings\": None,\n",
        "        \"debts\": None,\n",
        "        \"investments\": None,\n",
        "        \"financial_goals\": [],\n",
        "        \"conversation_history\": [],\n",
        "        \"spending_data\": generate_synthetic_spending_data()\n",
        "    }\n",
        "    save_profile(profile)\n",
        "    return profile\n",
        "\n",
        "def update_profile(profile, key, value):\n",
        "    \"\"\"Update a specific field in the user profile.\"\"\"\n",
        "    profile[key] = value\n",
        "    save_profile(profile)\n",
        "\n",
        "def get_profile_summary(profile):\n",
        "    \"\"\"Generate a human-readable summary of the user profile.\"\"\"\n",
        "    summary = f\"Based on your profile, {profile['name']}:\\n\"\n",
        "    for key, value in profile.items():\n",
        "        if key not in [\"id\", \"name\", \"conversation_history\", \"spending_data\"] and value is not None and value != []:\n",
        "            summary += f\"- Your {key.replace('_', ' ')}: {value}\\n\"\n",
        "    return wrap_text(summary.strip())"
      ],
      "metadata": {
        "id": "d6HD-W6tn-Ee"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment analyze for given text from user and get the context of text"
      ],
      "metadata": {
        "id": "U4mFBYjboRfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    \"\"\"Analyze the sentiment of the given text using the sentiment analyzer or a fallback method.\"\"\"\n",
        "    if sentiment_analyzer:\n",
        "        try:\n",
        "            result = sentiment_analyzer(text)[0]\n",
        "            return result['label'], result['score']\n",
        "        except Exception as e:\n",
        "            print(f\"Error in sentiment analysis: {e}\")\n",
        "\n",
        "    # Fallback simple sentiment analysis\n",
        "    positive_words = set(['good', 'great', 'happy', 'positive', 'optimistic'])\n",
        "    negative_words = set(['bad', 'terrible', 'sad', 'negative', 'worried', 'concerned'])\n",
        "\n",
        "    words = text.lower().split()\n",
        "    positive_count = sum(word in positive_words for word in words)\n",
        "    negative_count = sum(word in negative_words for word in words)\n",
        "\n",
        "    if positive_count > negative_count:\n",
        "        return 'POSITIVE', 0.7\n",
        "    elif negative_count > positive_count:\n",
        "        return 'NEGATIVE', 0.7\n",
        "    else:\n",
        "        return 'NEUTRAL', 0.5"
      ],
      "metadata": {
        "id": "CF8CCwctoUMI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_financial_context(text):\n",
        "    \"\"\"Determine the financial context of the given text using regex patterns.\"\"\"\n",
        "    patterns = {\n",
        "        'spending': r'\\b(buy|purchase|spend)\\b',\n",
        "        'saving': r'\\b(save|deposit)\\b',\n",
        "        'investment': r'\\b(invest|stock|bond)\\b',\n",
        "        'debt': r'\\b(debt|loan|borrow)\\b',\n",
        "        'income': r'\\b(income|salary|pension)\\b'\n",
        "    }\n",
        "\n",
        "    contexts = [context for context, pattern in patterns.items() if re.search(pattern, text, re.IGNORECASE)]\n",
        "    return contexts if contexts else ['general']"
      ],
      "metadata": {
        "id": "9Ne0-Ct_oiap"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate AI response to the user"
      ],
      "metadata": {
        "id": "OTXn9qzAop7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(profile, user_input):\n",
        "    \"\"\"Generate an AI response based on the user's input, profile, and spending data.\"\"\"\n",
        "    if not user_input.strip():\n",
        "        return \"I'm sorry, but I didn't receive any input. Could you please provide some information or ask a question?\"\n",
        "\n",
        "    try:\n",
        "        sentiment, confidence = analyze_sentiment(user_input)\n",
        "        contexts = get_financial_context(user_input)\n",
        "\n",
        "        profile_summary = get_profile_summary(profile)\n",
        "\n",
        "        # Analyze spending data if available\n",
        "        spending_insights = \"\"\n",
        "        if 'spending_data' in profile and profile['spending_data']:\n",
        "            insights = analyze_spending_data(profile['spending_data'])\n",
        "            spending_insights = f\"\\n\\nBased on your spending data for the last 5 years:\\n\"\n",
        "            spending_insights += f\"- Total spending: ${insights['total_spending']:.2f}\\n\"\n",
        "            spending_insights += f\"- Average monthly spending: ${insights['average_monthly_spending']:.2f}\\n\"\n",
        "            spending_insights += \"- Spending breakdown by category:\\n\"\n",
        "            for category, percentage in insights['category_breakdown'].items():\n",
        "                spending_insights += f\"  - {category.capitalize()}: {percentage:.2%}\\n\"\n",
        "\n",
        "        prompt = f\"The elderly client (Name: {profile['name']}, Age: {profile.get('age', 'Unknown')}) said: '{user_input}'. Their sentiment is {sentiment.lower()} (confidence: {confidence:.2f}). \"\n",
        "        prompt += f\"The financial context is related to {', '.join(contexts)}. \"\n",
        "        prompt += f\"\\n\\nUser's financial profile:\\n{profile_summary}\\n\"\n",
        "        prompt += spending_insights\n",
        "        prompt += \"\\nProvide an empathetic response and appropriate financial advice, considering their emotional state, financial context, profile information, and spending habits if available.\"\n",
        "\n",
        "        profile[\"conversation_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
        "        profile[\"conversation_history\"].append({\"role\": \"system\", \"content\": prompt})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=profile[\"conversation_history\"],\n",
        "            max_tokens=200,\n",
        "            n=1,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "\n",
        "        ai_response = response.choices[0].message.content.strip()\n",
        "        profile[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "        save_profile(profile)\n",
        "\n",
        "        return ai_response\n",
        "    except openai.APIError as e:\n",
        "        print(f\"OpenAI API error: {e}\")\n",
        "        return \"I apologize, but I'm having trouble connecting to my knowledge base. Could we try again in a moment?\"\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        return \"I'm sorry, but I encountered an unexpected error. Could you please try rephrasing your question?\"\n"
      ],
      "metadata": {
        "id": "ptb3bjP5ovyp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start conversation, update profile from the given and sanitize this input"
      ],
      "metadata": {
        "id": "oIfXrHibpCuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_profile_from_input(profile, user_input):\n",
        "    \"\"\"Update the user profile based on the input provided.\"\"\"\n",
        "    if \"income\" in user_input.lower():\n",
        "        match = re.search(r'\\d+', user_input)\n",
        "        if match:\n",
        "            update_profile(profile, \"income\", int(match.group()))\n",
        "    elif \"savings\" in user_input.lower():\n",
        "        match = re.search(r'\\d+', user_input)\n",
        "        if match:\n",
        "            update_profile(profile, \"savings\", int(match.group()))\n",
        "    elif \"debt\" in user_input.lower():\n",
        "        match = re.search(r'\\d+', user_input)\n",
        "        if match:\n",
        "            update_profile(profile, \"debts\", int(match.group()))\n",
        "    elif \"invest\" in user_input.lower():\n",
        "        update_profile(profile, \"investments\", user_input)\n",
        "    elif \"goal\" in user_input.lower():\n",
        "        profile[\"financial_goals\"].append(user_input)\n",
        "        save_profile(profile)\n",
        "\n",
        "def sanitize_input(user_input):\n",
        "    \"\"\"Sanitize user input to remove potentially harmful characters.\"\"\"\n",
        "    sanitized = re.sub(r'[^\\w\\s.,!?]', '', user_input)\n",
        "    return sanitized[:500]  # Limit input length\n",
        "\n",
        "\n",
        "def start_new_conversation():\n",
        "    \"\"\"Start a new conversation by getting or creating a user profile.\"\"\"\n",
        "    name = input(\"Please enter your name: \")\n",
        "    matching_profiles = find_profile_by_name(name)\n",
        "\n",
        "    if not matching_profiles:\n",
        "        profile = create_new_profile(name)\n",
        "        print(wrap_text(f\"Welcome, {profile['name']}! Let's create your profile.\"))\n",
        "    elif len(matching_profiles) == 1:\n",
        "        profile = matching_profiles[0]\n",
        "        print(wrap_text(f\"Welcome back, {profile['name']}!\"))\n",
        "    else:\n",
        "        print(wrap_text(f\"Found multiple profiles with the name {name}.\"))\n",
        "        for i, p in enumerate(matching_profiles):\n",
        "            print(wrap_text(f\"{i+1}. Age: {p.get('age', 'Unknown')}, Income: {p.get('income', 'Unknown')}\"))\n",
        "        choice = int(input(\"Please choose the correct profile number: \")) - 1\n",
        "        profile = matching_profiles[choice]\n",
        "\n",
        "    if profile['age'] is None:\n",
        "        age = input(\"Please enter your age: \")\n",
        "        update_profile(profile, 'age', age)\n",
        "\n",
        "    print(get_profile_summary(profile))\n",
        "    return profile\n"
      ],
      "metadata": {
        "id": "3u70HyxOpLwX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate different syntetic data of spending habit for the users"
      ],
      "metadata": {
        "id": "3VmlxLHpph04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_spending_data(years=5):\n",
        "    \"\"\"Generate synthetic spending data for the last 5 years.\"\"\"\n",
        "    categories = ['groceries', 'utilities', 'entertainment', 'healthcare', 'transportation']\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=years*365)\n",
        "\n",
        "    data = []\n",
        "    current_date = start_date\n",
        "    while current_date <= end_date:\n",
        "        for category in categories:\n",
        "            amount = random.randint(50, 500)  # Random amount between 50 and 500\n",
        "            data.append({\n",
        "                'date': current_date.strftime('%Y-%m-%d'),\n",
        "                'category': category,\n",
        "                'amount': amount\n",
        "            })\n",
        "        current_date += timedelta(days=30)  # Move to next month\n",
        "\n",
        "    return data\n",
        "\n",
        "def analyze_spending_data(spending_data):\n",
        "    \"\"\"Analyze spending data and return insights.\"\"\"\n",
        "    total_spending = sum(item['amount'] for item in spending_data)\n",
        "    category_totals = {}\n",
        "    for item in spending_data:\n",
        "        category = item['category']\n",
        "        amount = item['amount']\n",
        "        if category in category_totals:\n",
        "            category_totals[category] += amount\n",
        "        else:\n",
        "            category_totals[category] = amount\n",
        "\n",
        "    insights = {\n",
        "        'total_spending': total_spending,\n",
        "        'average_monthly_spending': total_spending / (len(spending_data) / 5),  # Assuming 5 categories per month\n",
        "        'category_breakdown': {cat: amount / total_spending for cat, amount in category_totals.items()}\n",
        "    }\n",
        "    return insights\n",
        "\n",
        "def update_spending_data(profile, category, amount):\n",
        "    \"\"\"Add a new spending entry to the user's profile.\"\"\"\n",
        "    if 'spending_data' not in profile:\n",
        "        profile['spending_data'] = []\n",
        "\n",
        "    new_entry = {\n",
        "        'date': datetime.now().strftime('%Y-%m-%d'),\n",
        "        'category': category,\n",
        "        'amount': amount\n",
        "    }\n",
        "    profile['spending_data'].append(new_entry)\n",
        "    save_profile(profile)\n",
        "\n",
        "def wrap_text(text, width=80):\n",
        "    \"\"\"Wrap text to fit within a specified width.\"\"\"\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=width))\n"
      ],
      "metadata": {
        "id": "F6DuJdNoppVy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main program"
      ],
      "metadata": {
        "id": "6-Y33wL2pviC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a separator function\n",
        "def print_separator(char='=', length=80):\n",
        "    \"\"\"Print a separator line.\"\"\"\n",
        "    print(char * length)\n",
        "\n",
        "# Main program loop\n",
        "print(wrap_text(\"Financial Advisor Bot: Hello! I'm here to help you with your financial questions and concerns.\"))\n",
        "print_separator()\n",
        "\n",
        "while True:\n",
        "    action = input(\"Enter 'start' to begin a new conversation, or 'quit' to exit: \").lower()\n",
        "\n",
        "    if action == 'quit':\n",
        "        print_separator()\n",
        "        print(wrap_text(\"Thank you for using the Financial Advisor Bot. Goodbye!\"))\n",
        "        print_separator()\n",
        "        break\n",
        "    elif action == 'start':\n",
        "        profile = start_new_conversation()\n",
        "        print_separator()\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                user_input = input(\"You: \")\n",
        "                user_input = sanitize_input(user_input)\n",
        "\n",
        "                if user_input.lower() in ['exit', 'quit', 'bye']:\n",
        "                    print_separator()\n",
        "                    print(wrap_text(\"Financial Advisor Bot: Thank you for chatting with me. Take care and have a great day!\"))\n",
        "                    print_separator()\n",
        "                    save_profile(profile)\n",
        "                    break  # This breaks the inner loop\n",
        "\n",
        "                print_separator()\n",
        "                update_profile_from_input(profile, user_input)\n",
        "                response = generate_response(profile, user_input)\n",
        "                print(wrap_text(\"Financial Advisor Bot: \" + response))\n",
        "                print_separator()\n",
        "            except KeyboardInterrupt:\n",
        "                print_separator()\n",
        "                print(wrap_text(\"\\nFinancial Advisor Bot: It seems you want to end our conversation. Take care and have a great day!\"))\n",
        "                print_separator()\n",
        "                save_profile(profile)\n",
        "                break  # This breaks the inner loop\n",
        "            except Exception as e:\n",
        "                print_separator()\n",
        "                print(f\"An unexpected error occurred: {e}\")\n",
        "                print(wrap_text(\"Financial Advisor Bot: I'm having some technical difficulties. Let's start our conversation again.\"))\n",
        "                print_separator()\n",
        "                profile[\"conversation_history\"] = profile[\"conversation_history\"][:1]  # Reset conversation history\n",
        "                save_profile(profile)\n",
        "    else:\n",
        "        print_separator()\n",
        "        print(wrap_text(\"Invalid input. Please enter 'start' or 'quit'.\"))\n",
        "        print_separator()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhXxOikepxwf",
        "outputId": "3547cf4a-2688-4b95-891a-2cb635442c10"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Financial Advisor Bot: Hello! I'm here to help you with your financial questions\n",
            "and concerns.\n",
            "================================================================================\n",
            "Enter 'start' to begin a new conversation, or 'quit' to exit: start\n",
            "Please enter your name: Casper\n",
            "Welcome, Casper! Let's create your profile.\n",
            "Please enter your age: 85\n",
            "Based on your profile, Casper: - Your age: 85\n",
            "================================================================================\n",
            "You: I have a retirement income for 2000 EUR per month. Based on my spending habit, how much I can save per month? \n",
            "================================================================================\n",
            "Financial Advisor Bot: I understand that managing your finances during\n",
            "retirement can be challenging, especially when trying to strike a balance\n",
            "between enjoying your golden years and saving for the future. With a retirement\n",
            "income of 2000 EUR per month and an average monthly spending of 1379.75 EUR, it\n",
            "seems like you have some room to save each month.  Based on your current\n",
            "numbers, you could potentially save around 620.25 EUR per month. It's great that\n",
            "you have the discipline to track your spending habits and think about saving for\n",
            "the future.   If you're looking to increase your savings even more, consider\n",
            "reviewing your spending breakdown by category and see if there are any areas\n",
            "where you could cut back or make more cost-effective choices. This could help\n",
            "you boost your savings and potentially achieve your financial goals sooner.\n",
            "Remember, it's important to strike a balance between enjoying your retirement\n",
            "and securing your financial future. If you have any specific financial goals or\n",
            "concerns, feel free to share them, and I'd be happy to\n",
            "================================================================================\n",
            "You: quit\n",
            "================================================================================\n",
            "Financial Advisor Bot: Thank you for chatting with me. Take care and have a\n",
            "great day!\n",
            "================================================================================\n",
            "Enter 'start' to begin a new conversation, or 'quit' to exit: quit\n",
            "================================================================================\n",
            "Thank you for using the Financial Advisor Bot. Goodbye!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOyGv662pQdi"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}